1: началось всё с того, решил поставить два пода оператора
2: попробовал отключить ноду сразу с подом оператора и с инстансом постгреса:
в конечном итоге оказалось всё завязанным на операторе, который рулил тем
кто будет следующим мастером, приёмники на реплике отключились автоматически
это радует. После того, как kubelet обнаружил, что все поды порушились,
то он восстановил под оператора на другой ноде и потом нормально мастера
поменял, дальше реплика поднялась, вроде, нормально.
3: потом поставил два инстанса оператора и он в начале работал не совсем
как надо, но после перезагрузки он начал переключаться между операторами
через выборы лидера, не очень хочется отдавать это на kubernetes, но,
похоже, подругому это не организуешь
начались приколы: когда я останавливаю ноду с оператором основным и
с мастером постгреса, то есть оператор меняет под и потом выполняет
переключение мастера. Однако когда поднимается нода со старым мастером,
то он не может нормально считать wal через pg_rewind
TODO: почему-то ещё генерируется куча логов, которые видеть так-то не хочется
но когда не происходит переключение, то объём wal остаётся таким же
4: почистил кластер и выполнил переключение такое же, но оператор находился
на другой ноде, а убивал мастера. Он снова упал и конфиги испортил
5: вычистил оператор, оставил его одного, и снова убил ноду с мастером.
подождал пока в консоли отобразится информация о смерти подов на ноде,
включил ноду ииии... всё заработало, он выполнил pg_rewind накатил, значит
логи, объёмом чуть меньше 100мб и потом нормально присоедилился к мастеру.
6: провёл отключение ещё раз и не дождался появления ответа о отключении подов
и всё полетело с ошибкой соединения к первичному инстансу debug-non-wait.json
7: ещё раз отключил ту же ноду и он уже выдавал ошибку о неправильной
конфигурации и отсутствии команды восстановления.
8: патрони тоже генерирует много логов, уже почти полгигабайта навалил
9: после очистки хранилища всё прекрасно восстанавливается, на
объём хранилища грешить не получается, так как у патрони давно всё
должно было забиться
10: запустим убийство мастера на другой ноде и дождёмся ответа kubelet
убьём его вместе с одним оператором, поставлю ещё другой
11: тоже упало всё debug-two-new-oper-failover.json, при чём второй раз
с ошибкой о аварийном завершении подключения к серверу
это уже что-то интересное, а может быть и нет. Почему у патрони нет
такой проблемы?
12: а потом начинаются приколы с убитой конфигурацией, почему, не понятно
она по какой-то причине не обновляется
13: прочистить всё снова, выполнить сначала отключение пода главного
и снять всё подключения, которые идут к реплике и когда они завершаются
провести ту же операцию, но только с падением ноды и выжиданием долгим
А потом без выжидания тоже проследить
14: под восстанавливается адекватно и там не меняется ip, восстановление
происходит достаточно быстро
15: на падении ноды было выяснено, что инстанс получает конфигурацию
посредством запроса к первичному инстансу, скорее всего для
согласованноти параметров, патрони же так не делает, он забирает конфиги
прямо из секрета, поэтому она и не теряется
А второй раз запуск вообще не возможен, так как конфиги помирают и
не могут быть восстановлены
16: подождём пока все поды получат статус умерших
17: следующий раз запустим сразу
поды помечаются умершими через 10 минут
18: видимо там вся папка пытается копироваться
и где-то оно ломается нафиг

